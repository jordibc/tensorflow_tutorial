{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to follow the tutorial at https://www.tensorflow.org/get_started/get_started, and at the same time experiment with jupyter notebooks.\n",
    "\n",
    "So here it is. Lesson 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That would be the first thing we need to include, after installing TensorFlow (`pip3 install tensorflow`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a computation by defining a graph (a _model_ in tensorflow lingo, as in \"computational model\"). Its nodes are constants, parameters (_variables_, or \"trainable parameters\"), variables (_placeholders_) and operations. (Yes, I find the terminology a bit confusing.) Their interconnection defines the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0)  # constant\n",
    "node2 = tf.constant(4.0)  # constant\n",
    "node3 = node1 + node2     # computation that links to two other nodes\n",
    "a = tf.placeholder(dtype=tf.float32)      # variable (\"placeholder\")\n",
    "node4 = node3 + a         # another computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate a node, we create a _session_. We can then run the model for certain values given to the placeholders, by running the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.  9.]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(node4, {a: [1, 2]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating the graph for a linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variables (trainable parameters).\n",
    "W = tf.Variable([.3], dtype=tf.float64)\n",
    "b = tf.Variable([-.3], dtype=tf.float64)\n",
    "\n",
    "# Placeholders (variables).\n",
    "x = tf.placeholder(dtype=tf.float64)\n",
    "\n",
    "# Model (just another node, really, that connects the results of the others).\n",
    "linear_model = W * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables need to be initialized explicitely, running first this on the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model on training data we need to write a _loss function_. In practice, it's a node that, when evaluated, produces a number that is the lower the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(dtype=tf.float64)\n",
    "\n",
    "# Loss function. A node that computes the difference of our \"linear model\" node and the expeted results node.\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y))  # sum of the squares\n",
    "\n",
    "# Training data. When we feed the x values, we expect our model to produce something similar to these y values.\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like that, when evaluating the loss node on the training data, the result would be small:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(loss, {x: x_train, y: y_train}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not exciting. We will continue from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of diving into the tutorial, today we spent most of our time creating this notebook. But before day 3 we want to finish this section. Here it goes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a node that connects to the loss, and has the capability of going through the connected variables and change them, optimizing the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer.\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.02)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a _training loop_ that will result in values for our variables that minimize the loss. Each time we run the train node we just created, the variables in our graph will hopefully converge more towards the best possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-1.]  b: [ 1.]  loss: 1.42871868951e-21\n"
     ]
    }
   ],
   "source": [
    "# Training loop.\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x:x_train, y:y_train})\n",
    "\n",
    "# Results and the resulting value for the error function.\n",
    "curr_W, curr_b, curr_loss  = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "print(\"W: %s  b: %s  loss: %s\" % (curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next day, we will start with the [MNIST for beginners](https://www.tensorflow.org/get_started/mnist/beginners)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side notes on Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the linear regression program can be done much simpler using the tf.contrib.learn package. Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare list of features. We only have one real-valued feature. There are\n",
    "# many other types of columns that are more complicated and useful.\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f56e01d5668>, '_num_worker_replicas': 0, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_environment': 'local', '_task_id': 0, '_task_type': None, '_tf_random_seed': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_summary_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_save_checkpoints_secs': 600, '_model_dir': None, '_evaluation_master': ''}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpm62ydyx3\n"
     ]
    }
   ],
   "source": [
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# logistic regression, linear classification, logistic classification, and\n",
    "# many neural network classifiers and regressors. The following code\n",
    "# provides an estimator that does linear regression.\n",
    "estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use two data sets: one for training and one for evaluation\n",
    "# We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train,\n",
    "                                              batch_size=4,\n",
    "                                              num_epochs=1000)\n",
    "eval_input_fn = tf.contrib.learn.io.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /home/jordi/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpm62ydyx3/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.5, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1436.39\n",
      "INFO:tensorflow:loss = 0.0488201, step = 101 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1374.46\n",
      "INFO:tensorflow:loss = 0.0396304, step = 201 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1188.59\n",
      "INFO:tensorflow:loss = 0.00980587, step = 301 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1410.86\n",
      "INFO:tensorflow:loss = 0.00252571, step = 401 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1456.57\n",
      "INFO:tensorflow:loss = 0.00119089, step = 501 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1504.98\n",
      "INFO:tensorflow:loss = 0.00034581, step = 601 (0.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 1423.48\n",
      "INFO:tensorflow:loss = 7.90467e-05, step = 701 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1365.07\n",
      "INFO:tensorflow:loss = 1.9161e-05, step = 801 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1902.02\n",
      "INFO:tensorflow:loss = 8.60194e-06, step = 901 (0.053 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpm62ydyx3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.47306e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x7f56e01d54a8>, 'feature_columns': [_RealValuedColumn(column_name='x', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)], 'optimizer': None, 'gradient_clip_norm': None, 'joint_weights': False})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can invoke 1000 training steps by invoking the  method and passing the\n",
    "# training data set.\n",
    "estimator.fit(input_fn=input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /home/jordi/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-24-01:47:11\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpm62ydyx3/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-24-01:47:11\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.68278e-06\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /home/jordi/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-24-01:47:11\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpm62ydyx3/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-24-01:47:12\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.00265579\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    }
   ],
   "source": [
    "# Here we evaluate how well our model did.\n",
    "train_loss = estimator.evaluate(input_fn=input_fn)\n",
    "eval_loss = estimator.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the results for the model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: {'global_step': 1000, 'loss': 1.6827835e-06}\n",
      "eval loss: {'global_step': 1000, 'loss': 0.0026557927}\n"
     ]
    }
   ],
   "source": [
    "print(\"train loss: %r\"% train_loss)\n",
    "print(\"eval loss: %r\"% eval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eval data has a higher loss, but it is still close to zero. That is supposed to mean that we are learning properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try creating a custom model that is not built into TensorFlow to implement our own equivalent model to LinearRegressor using the knowledge of the lower level TensorFlow API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of sub-classing tf.contrib.learn.Estimator, we provide Estimator, a function model_fn that tells tf.contrib.learn how it can evaluate predictions, training steps, and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f56a81d8390>, '_num_worker_replicas': 0, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_environment': 'local', '_task_id': 0, '_task_type': None, '_tf_random_seed': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_summary_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_save_checkpoints_secs': 600, '_model_dir': None, '_evaluation_master': ''}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpb8l5gcul\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model(features, labels, mode):\n",
    "  # Build a linear model and predict values\n",
    "  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "  y = W*features['x'] + b\n",
    "  # Loss sub-graph\n",
    "  loss = tf.reduce_sum(tf.square(y - labels))\n",
    "  # Training sub-graph\n",
    "  global_step = tf.train.get_global_step()\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "  train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "  # ModelFnOps connects subgraphs we built to the\n",
    "  # appropriate functionality.\n",
    "  return tf.contrib.learn.ModelFnOps(\n",
    "      mode=mode, predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.contrib.learn.Estimator(model_fn=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, 4, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpb8l5gcul/model.ckpt.\n",
      "INFO:tensorflow:loss = 99.2041000147, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1137.01\n",
      "INFO:tensorflow:loss = 0.153499242501, step = 101 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1513.16\n",
      "INFO:tensorflow:loss = 0.0140497510511, step = 201 (0.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 1367.18\n",
      "INFO:tensorflow:loss = 0.00316732801752, step = 301 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1417.49\n",
      "INFO:tensorflow:loss = 0.000142514244896, step = 401 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1503.55\n",
      "INFO:tensorflow:loss = 2.55092471665e-05, step = 501 (0.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 1637.8\n",
      "INFO:tensorflow:loss = 3.29001444816e-07, step = 601 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1335.64\n",
      "INFO:tensorflow:loss = 8.98038434244e-08, step = 701 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1049.87\n",
      "INFO:tensorflow:loss = 9.55069666317e-09, step = 801 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1048.27\n",
      "INFO:tensorflow:loss = 2.06948136027e-09, step = 901 (0.095 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpb8l5gcul/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.66354688372e-10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Estimator(params=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "estimator.fit(input_fn=input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-06-24-01:47:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpb8l5gcul/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-24-01:47:14\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.42345e-10\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-24-01:47:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpb8l5gcul/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-24-01:47:15\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101027\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    }
   ],
   "source": [
    "# Here we evaluate how well our model did. \n",
    "train_loss = estimator.evaluate(input_fn=input_fn)\n",
    "eval_loss = estimator.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the results this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: {'global_step': 1000, 'loss': 1.4234476e-10}\n",
      "eval loss: {'global_step': 1000, 'loss': 0.010102653}\n"
     ]
    }
   ],
   "source": [
    "print(\"train loss: %r\"% train_loss)\n",
    "print(\"eval loss: %r\"% eval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boy, was that verbose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We looked at MNIST today. Because this is a whole new session of TensorFlow, I think it makes sense to create a new notebook for it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
